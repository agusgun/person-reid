{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Using LFW Dataset - Facenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several feature extractor:\n",
    "1. Face Embedding: Facenet\n",
    "2. Face Embedding: VGG Face\n",
    "3. Face Embedding: VGG Face - VGG16\n",
    "4. Face Embedding: VGG Face - RESNET50\n",
    "5. LBPH (Local Binary Pattern Histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agusgun/anaconda3/envs/basic/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from keras import backend as K\n",
    "from feature_extractor.face_feature_extractor import FaceFeatureExtractor\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = '../lfw/'\n",
    "image_path_list = []\n",
    "labels = []\n",
    "name_dictionary = {}\n",
    "counter = 0\n",
    "for root, dirs, files in os.walk(DIR_PATH):\n",
    "    for filename in files:\n",
    "        person_name = ' '.join(filename.split('.')[0].split('_')[0:-1]) \n",
    "        file_path = os.path.join(root, filename)\n",
    "        if person_name not in name_dictionary:\n",
    "            counter += 1\n",
    "            name_dictionary[person_name] = counter\n",
    "        image_path_list.append(file_path)\n",
    "        labels.append(name_dictionary[person_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13233\n",
      "13233\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "print(len(image_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../lfw/Ryan_Newman/Ryan_Newman_0001.jpg',\n",
       " '../lfw/Dimitar_Berbatov/Dimitar_Berbatov_0001.jpg',\n",
       " '../lfw/Ed_Rendell/Ed_Rendell_0001.jpg',\n",
       " '../lfw/Joe_Crede/Joe_Crede_0001.jpg',\n",
       " '../lfw/Norman_Mailer/Norman_Mailer_0001.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(zip(image_path_list, labels))\n",
    "random.Random(0).shuffle(temp) # custom seed\n",
    "image_path_list, labels = zip(*temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../lfw/Tommy_Maddox/Tommy_Maddox_0001.jpg',\n",
       " '../lfw/David_Millar/David_Millar_0001.jpg',\n",
       " '../lfw/Gregg_Popovich/Gregg_Popovich_0004.jpg',\n",
       " '../lfw/Shimon_Peres/Shimon_Peres_0001.jpg',\n",
       " '../lfw/Rudolph_Giuliani/Rudolph_Giuliani_0024.jpg')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3038, 1517, 3115, 834, 1016)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dictionary['John Ashcroft']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACENET_MODEL_PATH = 'model_data/facenet/20180402-114759'\n",
    "VGGFACE_MODEL_PATH = 'model_data/vgg_face_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/agusgun/anaconda3/envs/basic/lib/python3.6/site-packages/mtcnn/layer_factory.py:211: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/agusgun/anaconda3/envs/basic/lib/python3.6/site-packages/mtcnn/layer_factory.py:213: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "mtcnn_detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_representation_list, true_label, test_representation, min_distance):\n",
    "    minimum_label = None\n",
    "    minimum_distance = min_distance\n",
    "    \n",
    "    for idx, image_representation in enumerate(image_representation_list):\n",
    "        distance = euclidean(image_representation, test_representation)\n",
    "        if distance < minimum_distance:\n",
    "            minimum_distance = distance\n",
    "            minimum_label = true_label[idx]\n",
    "    \n",
    "    return minimum_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(predictions, labels):\n",
    "    count_same = 0\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        if labels[idx] == prediction:\n",
    "            count_same += 1\n",
    "    return count_same / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_keypoints(point, x, y):\n",
    "    return (point[0] - x, point[1] - y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on experiment Facenet have distance below 0.9 for euclidean if two image are the same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: model_data/facenet/20180402-114759\n",
      "Metagraph file: model-20180402-114759.meta\n",
      "Checkpoint file: model-20180402-114759.ckpt-275\n",
      "WARNING:tensorflow:From /home/agusgun/anaconda3/envs/basic/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Restoring parameters from model_data/facenet/20180402-114759/model-20180402-114759.ckpt-275\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FaceFeatureExtractor(FACENET_MODEL_PATH, extractor_name='facenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_representation_database = []\n",
    "image_representation_labels = []\n",
    "prediction_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 1000\n",
      "0.348\n",
      "Checkpoint 2000\n",
      "0.3245\n",
      "Checkpoint 3000\n",
      "0.27466666666666667\n",
      "Checkpoint 4000\n",
      "0.248\n",
      "Checkpoint 5000\n",
      "0.2122\n",
      "Checkpoint 6000\n",
      "0.199\n",
      "Checkpoint 7000\n",
      "0.187\n",
      "Checkpoint 8000\n",
      "0.17925\n",
      "Checkpoint 9000\n",
      "0.17177777777777778\n",
      "Checkpoint 10000\n",
      "0.1657\n",
      "Checkpoint 11000\n",
      "0.15972727272727272\n",
      "Checkpoint 12000\n",
      "0.15508333333333332\n",
      "Checkpoint 13000\n",
      "0.14869230769230768\n",
      "CPU times: user 2h 16min 30s, sys: 1h 58min 56s, total: 4h 15min 26s\n",
      "Wall time: 46min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx, image_path in enumerate(image_path_list):\n",
    "    if idx % 1000 == 0 and idx > 0:\n",
    "        print(\"Checkpoint\", idx)\n",
    "        print(compute_score(prediction_result, labels))\n",
    "    img = cv.cvtColor(cv.imread(image_path), cv.COLOR_BGR2RGB)\n",
    "    detection_result = mtcnn_detector.detect_faces(img)\n",
    "    cropped_image = None\n",
    "    for face in detection_result:\n",
    "        face_bbox = face['box']\n",
    "        x, y, w, h = face_bbox\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        \n",
    "        keypoints = face['keypoints']\n",
    "        # Normalize position\n",
    "        le_pos = normalize_keypoints(keypoints['left_eye'], x, y) \n",
    "        re_pos =  normalize_keypoints(keypoints['right_eye'], x, y)\n",
    "        nose_pos =  normalize_keypoints(keypoints['nose'], x, y)\n",
    "        ml_pos =  normalize_keypoints(keypoints['mouth_left'], x, y)\n",
    "        mr_pos =  normalize_keypoints(keypoints['mouth_right'], x, y)\n",
    "        \n",
    "        dX = re_pos[0] - le_pos[0]\n",
    "        dY = re_pos[1] - le_pos[1]\n",
    "        angle = np.degrees(np.arctan2(dY, dX))\n",
    "        \n",
    "        # Affine transformation\n",
    "        scale = 1\n",
    "        eyes_center = ((le_pos[0] + re_pos[0]) // 2, (le_pos[1] + re_pos[1]) // 2)\n",
    "        M = cv.getRotationMatrix2D(eyes_center, angle, scale)\n",
    "        cropped_image = cv.warpAffine(cropped_image, M, (w, h), cv.INTER_CUBIC)\n",
    "        break\n",
    "    if not cropped_image is None:\n",
    "        feature_test = feature_extractor.extract_image(cropped_image)\n",
    "        prediction = predict(image_representation_database, image_representation_labels, feature_test, THRESHOLD)\n",
    "        if prediction == None:\n",
    "            label = labels[idx]\n",
    "            if label not in image_representation_labels:\n",
    "                image_representation_labels.append(label)\n",
    "                image_representation_database.append(feature_test)\n",
    "                prediction_result.append(label)\n",
    "            else: # false prediction\n",
    "                prediction_result.append(-1) \n",
    "        else:\n",
    "            prediction_result.append(prediction)\n",
    "    else: # failed to detect faces\n",
    "        prediction_result.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../lfw/Abdullah_Gul/Abdullah_Gul_0007.jpg'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_list[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14773671880903802"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(prediction_result, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13233"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13233"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor.extractor.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list = sorted(image_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../lfw/Abdullah_Gul/Abdullah_Gul_0001.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0002.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0003.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0004.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0005.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0006.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0007.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0008.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0009.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0010.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0011.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0012.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0013.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0014.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0015.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0016.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0017.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0018.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0019.jpg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_list[31:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 0\n",
      "CPU times: user 527 ms, sys: 593 ms, total: 1.12 s\n",
      "Wall time: 178 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx, image_path in enumerate(image_path_list[31:32]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"Checkpoint\", idx)\n",
    "    img = cv.cvtColor(cv.imread(image_path), cv.COLOR_BGR2RGB)\n",
    "    detection_result = mtcnn_detector.detect_faces(img)\n",
    "    cropped_image = None\n",
    "    for face in detection_result:\n",
    "        face_bbox = face['box']\n",
    "        x, y, w, h = face_bbox\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        \n",
    "        keypoints = face['keypoints']\n",
    "        # Normalize position\n",
    "        le_pos = normalize_keypoints(keypoints['left_eye'], x, y) \n",
    "        re_pos =  normalize_keypoints(keypoints['right_eye'], x, y)\n",
    "        nose_pos =  normalize_keypoints(keypoints['nose'], x, y)\n",
    "        ml_pos =  normalize_keypoints(keypoints['mouth_left'], x, y)\n",
    "        mr_pos =  normalize_keypoints(keypoints['mouth_right'], x, y)\n",
    "        \n",
    "        dX = re_pos[0] - le_pos[0]\n",
    "        dY = re_pos[1] - le_pos[1]\n",
    "        angle = np.degrees(np.arctan2(dY, dX))\n",
    "        \n",
    "        # Affine transformation\n",
    "        scale = 1\n",
    "        eyes_center = ((le_pos[0] + re_pos[0]) // 2, (le_pos[1] + re_pos[1]) // 2)\n",
    "        M = cv.getRotationMatrix2D(eyes_center, angle, scale)\n",
    "        cropped_image = cv.warpAffine(cropped_image, M, (w, h), cv.INTER_CUBIC)\n",
    "        break\n",
    "    \n",
    "    if not cropped_image is None:\n",
    "        feature_test = feature_extractor.extract_image(cropped_image)\n",
    "        prediction = predict(image_representation_database, image_representation_labels, feature_test, THRESHOLD)\n",
    "        if prediction == None:\n",
    "            label = labels[idx]\n",
    "            if label not in image_representation_labels:\n",
    "                image_representation_labels.append(label)\n",
    "                image_representation_database.append(feature_test)\n",
    "                prediction_result.append(label)\n",
    "            else: # false prediction\n",
    "                prediction_result.append(-1) \n",
    "        else:\n",
    "            prediction_result.append(prediction)\n",
    "    else: # failed to detect faces\n",
    "        prediction_result.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.78268175e-02,  3.25670764e-02,  4.05604392e-02,  3.39724659e-03,\n",
       "        5.37126437e-02,  3.68385874e-02, -3.60369831e-02, -1.73444413e-02,\n",
       "        8.96531567e-02, -4.92382273e-02,  6.34373799e-02, -4.30092923e-02,\n",
       "        1.38749322e-02, -2.25634258e-02,  5.25098713e-03, -5.53738847e-02,\n",
       "       -2.98285335e-02,  3.73244248e-02,  2.42847018e-02, -8.39974079e-03,\n",
       "       -4.18943465e-02,  2.79076807e-02,  1.68454982e-02, -9.15986672e-02,\n",
       "       -6.12437464e-02,  4.28005122e-03,  3.90765490e-03, -7.52496067e-03,\n",
       "       -4.01982926e-02,  2.21072044e-02,  1.55353844e-02,  8.68968144e-02,\n",
       "        5.28657362e-02,  2.58001499e-02,  6.26789108e-02, -5.48725091e-02,\n",
       "        2.25371365e-02, -6.22436218e-02,  1.20208515e-02,  2.69103255e-02,\n",
       "        6.34750202e-02, -7.82843903e-02, -2.62630619e-02,  4.75831330e-02,\n",
       "        2.00108066e-02, -3.07505000e-02, -5.62555566e-02,  1.24266259e-02,\n",
       "       -4.64748703e-02, -7.86072314e-02, -3.78704518e-02, -4.81357537e-02,\n",
       "       -3.58574651e-02,  6.84873760e-02,  2.49830019e-02, -4.50278400e-03,\n",
       "        5.00294752e-02, -4.96397242e-02, -9.44191217e-03, -8.37599952e-03,\n",
       "        2.20422000e-02,  4.47520018e-02, -1.91448256e-02, -4.46839891e-02,\n",
       "       -3.76150524e-03,  4.04033251e-02,  1.95317417e-02, -5.93339838e-02,\n",
       "       -3.18899415e-02, -4.17727418e-02,  7.65857249e-02, -3.51633057e-02,\n",
       "       -2.98388917e-02, -2.74406821e-02,  2.20436808e-02,  3.09310239e-02,\n",
       "        4.30288091e-02, -8.82979296e-03, -7.65084177e-02, -1.04405435e-05,\n",
       "        9.87338275e-03,  4.33956906e-02,  1.06950309e-02, -2.73758639e-02,\n",
       "        3.37325819e-02, -2.43598334e-02,  1.51553769e-02, -2.53784098e-02,\n",
       "        2.43352149e-02, -7.52550550e-03,  1.53110083e-02, -1.06333476e-02,\n",
       "        6.43209666e-02, -2.36639418e-02,  3.07029877e-02,  6.33975640e-02,\n",
       "       -7.49797970e-02,  5.65448031e-02, -8.99676308e-02,  4.60512824e-02,\n",
       "        2.73109670e-03,  1.85172167e-03,  2.68760938e-02,  4.06207331e-02,\n",
       "       -7.69436434e-02,  6.33146167e-02,  8.06871429e-02,  2.79920399e-02,\n",
       "       -8.47954974e-02,  4.37450819e-02, -1.93199590e-02, -1.46160983e-02,\n",
       "       -8.64216909e-02,  1.64311826e-02, -7.90940672e-02,  3.67791392e-02,\n",
       "       -2.37381291e-02,  1.28127843e-01,  7.77558908e-02,  6.96373656e-02,\n",
       "       -3.80083770e-02, -4.56948541e-02,  1.90294683e-02,  5.73126301e-02,\n",
       "       -4.70847078e-02,  5.80979453e-04,  1.70253462e-03, -5.81065230e-02,\n",
       "       -4.73135784e-02, -7.05131739e-02, -1.35034351e-02, -6.62179142e-02,\n",
       "       -8.74670316e-03, -5.83815435e-03, -4.88057360e-03,  7.53907785e-02,\n",
       "        2.86940136e-03, -9.88689885e-02, -7.21091107e-02, -2.26715710e-02,\n",
       "       -3.96853760e-02,  9.33636539e-03, -1.28437504e-01,  2.44395342e-02,\n",
       "        4.21830863e-02,  1.76120624e-02, -2.37343498e-02,  1.32821035e-02,\n",
       "       -2.79194228e-02, -4.12701443e-02,  3.30337249e-02,  4.54879329e-02,\n",
       "       -6.77464232e-02,  8.29690415e-03,  3.09906099e-02, -4.98397369e-03,\n",
       "       -4.04868908e-02, -3.95706622e-03,  4.64684740e-02,  8.93366616e-03,\n",
       "       -2.08242121e-03,  3.08739524e-02, -6.24003634e-02,  4.17271592e-02,\n",
       "       -9.47514549e-03, -3.72186154e-02,  3.45445499e-02,  3.18171494e-02,\n",
       "        1.71575192e-02,  7.51883984e-02, -8.07966758e-03,  1.00656532e-01,\n",
       "       -3.44508328e-02, -3.65788303e-02, -2.84139812e-02, -9.49114654e-03,\n",
       "        1.55848451e-02, -2.52287760e-02, -6.62523955e-02, -3.14981155e-02,\n",
       "        8.18400308e-02,  9.71602723e-02, -3.97329032e-02,  5.22196405e-02,\n",
       "        3.35171670e-02, -1.01891368e-04,  6.56568073e-03,  2.25059073e-02,\n",
       "        5.99372722e-02, -1.03308586e-02,  3.15769166e-02, -6.80694263e-03,\n",
       "        3.81341539e-02,  7.83983245e-03, -1.85828395e-02, -8.19744244e-02,\n",
       "        1.47761591e-02, -9.44183487e-03, -2.02663951e-02,  5.95086394e-03,\n",
       "        6.37471899e-02, -3.08545977e-02,  5.99655695e-02,  6.00348935e-02,\n",
       "       -4.35920581e-02,  3.81354094e-02, -2.49579810e-02, -4.56112772e-02,\n",
       "        2.30771322e-02,  1.23673670e-01,  7.81869069e-02, -6.67117089e-02,\n",
       "       -6.13687597e-02,  2.09320430e-02, -4.03257832e-02, -3.75788882e-02,\n",
       "       -1.25799151e-02, -1.39499325e-02,  3.01031880e-02, -2.45347060e-03,\n",
       "        5.68615645e-02, -1.09741827e-02,  7.28621008e-03,  2.17499631e-03,\n",
       "       -4.75950688e-02,  4.04699109e-02,  8.23782608e-02, -3.99459191e-02,\n",
       "       -7.37465099e-02,  4.66226302e-02, -7.35356659e-03, -3.19982972e-03,\n",
       "       -4.57836548e-03,  3.96076627e-02, -2.36702282e-02,  9.17484760e-02,\n",
       "       -3.98976803e-02,  2.00149585e-02, -4.06665988e-02,  9.23734307e-02,\n",
       "       -3.49496305e-02,  6.37042895e-02,  1.20220697e-02, -1.93539634e-02,\n",
       "       -2.72943284e-02, -2.91409623e-02, -5.31942071e-03, -2.65398510e-02,\n",
       "        4.80300635e-02,  2.80781649e-02,  4.08147741e-03, -3.30358557e-02,\n",
       "       -1.79788060e-02, -3.69591862e-02,  4.05980274e-02,  4.50149514e-02,\n",
       "        6.45383820e-02,  1.63703877e-02,  1.41600696e-02,  2.29738820e-02,\n",
       "       -3.13187507e-03,  5.47990054e-02,  6.21269755e-02, -3.83657329e-02,\n",
       "       -4.20225635e-02,  4.43168618e-02,  1.73819661e-02,  1.69356596e-02,\n",
       "       -6.65881634e-02, -8.96522105e-02,  2.81361700e-03, -1.93813108e-02,\n",
       "        1.39605924e-02, -1.74387340e-02,  9.47713852e-02,  3.91371511e-02,\n",
       "        4.16518515e-03, -4.02902439e-02,  1.32971732e-02, -6.19317545e-03,\n",
       "        3.05251442e-02,  9.17384997e-02, -4.27903607e-02, -4.18544933e-03,\n",
       "       -5.50843775e-02, -3.84222567e-02,  5.41345216e-03,  2.38496717e-02,\n",
       "        3.11157550e-03, -1.27390213e-03, -1.30722104e-02, -1.21718748e-02,\n",
       "       -1.56569388e-02, -4.45071198e-02, -1.53592285e-02, -2.30686273e-02,\n",
       "        6.24544360e-02, -3.62050831e-02,  4.27934434e-03,  7.59188132e-03,\n",
       "       -8.28264505e-02, -8.05209111e-03, -2.50275899e-02, -1.42875584e-02,\n",
       "       -4.67927605e-02,  5.17145358e-03,  3.11281886e-02,  5.60480468e-02,\n",
       "       -6.89038187e-02, -7.41078565e-03, -4.57014591e-02,  2.13470105e-02,\n",
       "        1.06588915e-01, -1.40599292e-02, -4.54066396e-02,  5.65332249e-02,\n",
       "        2.75107729e-03, -1.13046868e-03,  8.00837949e-02,  6.92006806e-03,\n",
       "        3.89894396e-02, -2.65918635e-02,  4.52091917e-02, -1.23427128e-02,\n",
       "        6.49897903e-02, -9.46658999e-02,  1.28332391e-01,  4.62089889e-02,\n",
       "        4.48289774e-02,  1.20605389e-02,  3.73414718e-02, -1.31791122e-02,\n",
       "        3.30963433e-02,  7.52364621e-02, -9.82921664e-03,  8.11615288e-02,\n",
       "       -2.10558157e-02, -4.04546633e-02,  3.22720297e-02, -8.80998820e-02,\n",
       "       -8.64237454e-03, -5.59063768e-03,  1.49476370e-02, -1.39755988e-02,\n",
       "       -8.84713046e-03, -1.03587285e-02, -1.19023295e-02,  4.74285036e-02,\n",
       "       -1.20485626e-01,  3.48450616e-02, -5.71630262e-02,  6.11003768e-03,\n",
       "       -3.64304371e-02,  7.39570335e-02,  1.90175083e-02,  1.75335612e-02,\n",
       "        7.70279616e-02, -1.11599043e-02,  4.64708507e-02,  3.46342847e-02,\n",
       "       -4.14607264e-02,  5.26069403e-02, -4.68972791e-03,  1.37947761e-02,\n",
       "       -3.40217426e-02, -2.14800728e-03, -6.93599433e-02,  4.37623635e-02,\n",
       "       -1.84923541e-02,  5.34154624e-02,  5.48009500e-02, -4.54677641e-02,\n",
       "       -5.75842597e-02, -2.89074350e-02, -7.07556158e-02,  2.51892246e-02,\n",
       "        7.65373111e-02, -2.60576094e-03,  8.66790675e-03, -5.76288775e-02,\n",
       "        1.61515493e-02, -5.80995902e-02,  3.31543274e-02, -6.99886084e-02,\n",
       "       -7.36833513e-02, -1.89335309e-02, -4.56168056e-02, -3.65527123e-02,\n",
       "        3.46905589e-02, -2.48407163e-02,  3.60912690e-03, -1.35664595e-02,\n",
       "       -2.10175700e-02, -7.02396557e-02,  7.79800043e-02, -1.61688626e-02,\n",
       "        3.53719816e-02,  1.72146633e-02, -3.68388789e-03,  7.58520886e-03,\n",
       "       -7.63963209e-03,  1.53704183e-02, -4.93723899e-02,  4.81111603e-03,\n",
       "        3.76829058e-02,  1.87778268e-02, -2.52634995e-02, -8.81013125e-02,\n",
       "        6.29808381e-02, -1.60970527e-03, -2.83743646e-02, -1.69974111e-03,\n",
       "        8.06884766e-02, -4.76407446e-02,  4.84480597e-02, -5.94452675e-03,\n",
       "        4.41542547e-03,  4.73892177e-03,  9.96002089e-03,  3.80036086e-02,\n",
       "       -3.29409027e-04, -1.45467510e-02,  5.71587356e-03,  4.27949391e-02,\n",
       "        8.99745268e-04,  2.29953555e-03, -7.47709870e-02, -4.81990026e-03,\n",
       "       -3.99944074e-02, -5.55038042e-02, -1.09263016e-02,  6.04096614e-03,\n",
       "       -4.64856215e-02, -5.11842780e-03, -1.51185330e-03, -5.53250983e-02,\n",
       "        4.98002060e-02, -6.94997609e-02, -2.83502936e-02, -4.59759086e-02,\n",
       "       -3.21306437e-02, -2.12373361e-02, -6.64049461e-02,  3.19319703e-02,\n",
       "       -1.72430314e-02,  6.64079282e-03, -4.48786814e-05, -8.27634707e-02,\n",
       "       -9.29320455e-02,  5.17727844e-02, -2.65482832e-02,  2.91658398e-02,\n",
       "       -7.52489343e-02, -1.06872404e-02, -7.18809292e-02, -7.44505879e-03,\n",
       "       -7.06088245e-02,  3.10358796e-02, -1.89488765e-03,  8.48401487e-02,\n",
       "       -1.57772191e-02,  2.24040318e-02, -9.17643607e-02, -4.25658152e-02,\n",
       "        7.80206406e-03,  3.30910943e-02, -6.64556772e-02, -4.34220731e-02,\n",
       "        7.33086914e-02, -3.75773162e-02,  2.96451040e-02,  1.11214155e-02,\n",
       "       -7.53719360e-03, -2.07512826e-02,  5.50469346e-02, -6.05783472e-03,\n",
       "       -3.36177200e-02,  4.58616018e-02,  7.58517627e-03,  1.79376099e-02,\n",
       "        2.69804541e-02, -7.21364981e-03, -8.48759897e-03,  3.46127152e-02,\n",
       "       -6.86918348e-02,  5.57468645e-03, -1.64727271e-02, -3.21754962e-02,\n",
       "       -6.13744892e-02, -1.14482576e-02, -3.16926166e-02,  2.31838319e-02,\n",
       "       -7.27565214e-03, -8.17597061e-02, -1.58912931e-02, -3.64681929e-02,\n",
       "       -2.59346738e-02, -7.97288045e-02, -3.25581916e-02,  1.02630397e-03,\n",
       "       -4.07531634e-02, -2.76020542e-02, -5.37898531e-03, -7.51710450e-03,\n",
       "        3.25333774e-02,  2.03562267e-02, -2.27384130e-03, -6.35018423e-02,\n",
       "       -1.32504627e-02, -1.35573773e-02, -4.25875708e-02, -1.80318188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_feature = feature_test.copy()\n",
    "base_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 0\n",
      "0.0\n",
      "0.9450331330299377\n",
      "0.7808054089546204\n",
      "0.8431230187416077\n",
      "0.719917356967926\n",
      "0.6710638403892517\n",
      "0.5184654593467712\n",
      "0.855949342250824\n",
      "0.992148220539093\n",
      "0.7338433265686035\n",
      "0.7143685817718506\n",
      "0.5583601593971252\n",
      "0.5010948777198792\n",
      "0.691178560256958\n",
      "0.7147900462150574\n",
      "0.737917959690094\n",
      "0.5430542230606079\n",
      "0.7266527414321899\n",
      "0.6774882674217224\n",
      "CPU times: user 12.1 s, sys: 10.2 s, total: 22.2 s\n",
      "Wall time: 3.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx, image_path in enumerate(image_path_list[31:50]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"Checkpoint\", idx)\n",
    "    img = cv.cvtColor(cv.imread(image_path), cv.COLOR_BGR2RGB)\n",
    "    detection_result = mtcnn_detector.detect_faces(img)\n",
    "    cropped_image = None\n",
    "    for face in detection_result:\n",
    "        face_bbox = face['box']\n",
    "        x, y, w, h = face_bbox\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        \n",
    "        keypoints = face['keypoints']\n",
    "        # Normalize position\n",
    "        le_pos = normalize_keypoints(keypoints['left_eye'], x, y) \n",
    "        re_pos =  normalize_keypoints(keypoints['right_eye'], x, y)\n",
    "        nose_pos =  normalize_keypoints(keypoints['nose'], x, y)\n",
    "        ml_pos =  normalize_keypoints(keypoints['mouth_left'], x, y)\n",
    "        mr_pos =  normalize_keypoints(keypoints['mouth_right'], x, y)\n",
    "        \n",
    "        dX = re_pos[0] - le_pos[0]\n",
    "        dY = re_pos[1] - le_pos[1]\n",
    "        angle = np.degrees(np.arctan2(dY, dX))\n",
    "        \n",
    "        # Affine transformation\n",
    "        scale = 1\n",
    "        eyes_center = ((le_pos[0] + re_pos[0]) // 2, (le_pos[1] + re_pos[1]) // 2)\n",
    "        M = cv.getRotationMatrix2D(eyes_center, angle, scale)\n",
    "        cropped_image = cv.warpAffine(cropped_image, M, (w, h), cv.INTER_CUBIC)\n",
    "        break\n",
    "    \n",
    "    if not cropped_image is None:\n",
    "        feature_test = feature_extractor.extract_image(cropped_image)\n",
    "        distance = euclidean(feature_test, base_feature)\n",
    "        print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 0\n",
      "1.4553213119506836\n",
      "1.58197021484375\n",
      "1.684726595878601\n",
      "1.4819999933242798\n",
      "1.422335147857666\n",
      "1.4219071865081787\n",
      "1.3882689476013184\n",
      "1.4149330854415894\n",
      "1.4556185007095337\n",
      "1.3702315092086792\n",
      "1.5404937267303467\n",
      "1.5120075941085815\n",
      "1.0301886796951294\n",
      "1.5865408182144165\n",
      "1.456681251525879\n",
      "1.2860819101333618\n",
      "1.4552093744277954\n",
      "1.43538236618042\n",
      "1.2492679357528687\n",
      "1.4601813554763794\n",
      "1.5615521669387817\n",
      "1.3907543420791626\n",
      "1.5302071571350098\n",
      "1.0118813514709473\n",
      "1.45500648021698\n",
      "1.2846486568450928\n",
      "1.2236195802688599\n",
      "1.2333000898361206\n",
      "1.2461092472076416\n",
      "1.3176668882369995\n",
      "AVG: 1.3981364488601684\n",
      "CPU times: user 21.4 s, sys: 22.4 s, total: 43.8 s\n",
      "Wall time: 7.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "for idx, image_path in enumerate(image_path_list[0:30]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"Checkpoint\", idx)\n",
    "    img = cv.cvtColor(cv.imread(image_path), cv.COLOR_BGR2RGB)\n",
    "    detection_result = mtcnn_detector.detect_faces(img)\n",
    "    cropped_image = None\n",
    "    for face in detection_result:\n",
    "        face_bbox = face['box']\n",
    "        x, y, w, h = face_bbox\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        \n",
    "        keypoints = face['keypoints']\n",
    "        # Normalize position\n",
    "        le_pos = normalize_keypoints(keypoints['left_eye'], x, y) \n",
    "        re_pos =  normalize_keypoints(keypoints['right_eye'], x, y)\n",
    "        nose_pos =  normalize_keypoints(keypoints['nose'], x, y)\n",
    "        ml_pos =  normalize_keypoints(keypoints['mouth_left'], x, y)\n",
    "        mr_pos =  normalize_keypoints(keypoints['mouth_right'], x, y)\n",
    "        \n",
    "        dX = re_pos[0] - le_pos[0]\n",
    "        dY = re_pos[1] - le_pos[1]\n",
    "        angle = np.degrees(np.arctan2(dY, dX))\n",
    "        \n",
    "        # Affine transformation\n",
    "        scale = 1\n",
    "        eyes_center = ((le_pos[0] + re_pos[0]) // 2, (le_pos[1] + re_pos[1]) // 2)\n",
    "        M = cv.getRotationMatrix2D(eyes_center, angle, scale)\n",
    "        cropped_image = cv.warpAffine(cropped_image, M, (w, h), cv.INTER_CUBIC)\n",
    "        break\n",
    "    \n",
    "    if not cropped_image is None:\n",
    "        feature_test = feature_extractor.extract_image(cropped_image)\n",
    "        distance = euclidean(feature_test, base_feature)\n",
    "        print(distance)\n",
    "        scores.append(distance)\n",
    "print(\"AVG:\", np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
