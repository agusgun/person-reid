{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Using LFW Dataset - Facenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several feature extractor:\n",
    "1. Face Embedding: Facenet\n",
    "2. Face Embedding: VGG Face\n",
    "3. Face Embedding: VGG Face - VGG16\n",
    "4. Face Embedding: VGG Face - RESNET50\n",
    "5. LBPH (Local Binary Pattern Histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/agusgun/anaconda3/envs/basic/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from keras import backend as K\n",
    "from feature_extractor.face_feature_extractor import FaceFeatureExtractor\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from mtcnn.mtcnn import MTCNN\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_PATH = '../lfw/'\n",
    "image_path_list = []\n",
    "labels = []\n",
    "name_dictionary = {}\n",
    "counter = 0\n",
    "for root, dirs, files in os.walk(DIR_PATH):\n",
    "    for filename in files:\n",
    "        person_name = ' '.join(filename.split('.')[0].split('_')[0:-1]) \n",
    "        file_path = os.path.join(root, filename)\n",
    "        if person_name not in name_dictionary:\n",
    "            counter += 1\n",
    "            name_dictionary[person_name] = counter\n",
    "        image_path_list.append(file_path)\n",
    "        labels.append(name_dictionary[person_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13233\n",
      "13233\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))\n",
    "print(len(image_path_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../lfw/Ryan_Newman/Ryan_Newman_0001.jpg',\n",
       " '../lfw/Dimitar_Berbatov/Dimitar_Berbatov_0001.jpg',\n",
       " '../lfw/Ed_Rendell/Ed_Rendell_0001.jpg',\n",
       " '../lfw/Joe_Crede/Joe_Crede_0001.jpg',\n",
       " '../lfw/Norman_Mailer/Norman_Mailer_0001.jpg']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_list[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = list(zip(image_path_list, labels))\n",
    "random.Random(0).shuffle(temp) # custom seed\n",
    "image_path_list, labels = zip(*temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../lfw/Tommy_Maddox/Tommy_Maddox_0001.jpg',\n",
       " '../lfw/David_Millar/David_Millar_0001.jpg',\n",
       " '../lfw/Gregg_Popovich/Gregg_Popovich_0004.jpg',\n",
       " '../lfw/Shimon_Peres/Shimon_Peres_0001.jpg',\n",
       " '../lfw/Rudolph_Giuliani/Rudolph_Giuliani_0024.jpg')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3038, 1517, 3115, 834, 1016)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "482"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dictionary['John Ashcroft']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "FACENET_MODEL_PATH = 'model_data/facenet/20180402-114759'\n",
    "VGGFACE_MODEL_PATH = 'model_data/vgg_face_weights.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/agusgun/anaconda3/envs/basic/lib/python3.6/site-packages/mtcnn/layer_factory.py:211: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/agusgun/anaconda3/envs/basic/lib/python3.6/site-packages/mtcnn/layer_factory.py:213: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "mtcnn_detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_representation_list, true_label, test_representation, min_distance):\n",
    "    minimum_label = None\n",
    "    minimum_distance = min_distance\n",
    "    \n",
    "    for idx, image_representation in enumerate(image_representation_list):\n",
    "        distance = euclidean(image_representation, test_representation)\n",
    "        if distance < minimum_distance:\n",
    "            minimum_distance = distance\n",
    "            minimum_label = true_label[idx]\n",
    "    \n",
    "    return minimum_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(predictions, labels):\n",
    "    count_same = 0\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        if labels[idx] == prediction:\n",
    "            count_same += 1\n",
    "    return count_same / len(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on experiment Facenet have distance below 0.9 for euclidean if two image are the same person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model directory: model_data/facenet/20180402-114759\n",
      "Metagraph file: model-20180402-114759.meta\n",
      "Checkpoint file: model-20180402-114759.ckpt-275\n",
      "WARNING:tensorflow:From /home/agusgun/anaconda3/envs/basic/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py:391: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Restoring parameters from model_data/facenet/20180402-114759/model-20180402-114759.ckpt-275\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FaceFeatureExtractor(FACENET_MODEL_PATH, extractor_name='facenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Starts Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_representation_database = []\n",
    "image_representation_labels = []\n",
    "prediction_result = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 0\n",
      "Checkpoint 1000\n",
      "Checkpoint 2000\n",
      "Checkpoint 3000\n",
      "Checkpoint 4000\n",
      "Checkpoint 5000\n",
      "Checkpoint 6000\n",
      "Checkpoint 7000\n",
      "Checkpoint 8000\n",
      "Checkpoint 9000\n",
      "Checkpoint 10000\n",
      "Checkpoint 11000\n",
      "Checkpoint 12000\n",
      "Checkpoint 13000\n",
      "CPU times: user 2h 23min 46s, sys: 2h 9min 49s, total: 4h 33min 35s\n",
      "Wall time: 56min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx, image_path in enumerate(image_path_list):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"Checkpoint\", idx)\n",
    "    img = cv.cvtColor(cv.imread(image_path), cv.COLOR_BGR2RGB)\n",
    "    detection_result = mtcnn_detector.detect_faces(img)\n",
    "    cropped_image = None\n",
    "    for face in detection_result:\n",
    "        face_bbox = face['box']\n",
    "        x, y, w, h = face_bbox\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        break\n",
    "    \n",
    "    if not cropped_image is None:\n",
    "        feature_test = feature_extractor.extract_image(cropped_image)\n",
    "        prediction = predict(image_representation_database, image_representation_labels, feature_test, THRESHOLD)\n",
    "        if prediction == None:\n",
    "            label = labels[idx]\n",
    "            if label not in image_representation_labels:\n",
    "                image_representation_labels.append(label)\n",
    "                image_representation_database.append(feature_test)\n",
    "                prediction_result.append(label)\n",
    "            else: # false prediction\n",
    "                prediction_result.append(-1) \n",
    "        else:\n",
    "            prediction_result.append(prediction)\n",
    "    else: # failed to detect faces\n",
    "        prediction_result.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../lfw/George_W_Bush/George_W_Bush_0233.jpg'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_list[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5910224438902744"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_score(prediction_result, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13233"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13233"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor.extractor.close_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_list = sorted(image_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../lfw/Abdullah_Gul/Abdullah_Gul_0001.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0002.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0003.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0004.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0005.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0006.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0007.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0008.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0009.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0010.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0011.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0012.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0013.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0014.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0015.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0016.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0017.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0018.jpg',\n",
       " '../lfw/Abdullah_Gul/Abdullah_Gul_0019.jpg']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path_list[31:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 0\n",
      "CPU times: user 580 ms, sys: 428 ms, total: 1.01 s\n",
      "Wall time: 181 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx, image_path in enumerate(image_path_list[31:32]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"Checkpoint\", idx)\n",
    "    img = cv.cvtColor(cv.imread(image_path), cv.COLOR_BGR2RGB)\n",
    "    detection_result = mtcnn_detector.detect_faces(img)\n",
    "    cropped_image = None\n",
    "    for face in detection_result:\n",
    "        face_bbox = face['box']\n",
    "        x, y, w, h = face_bbox\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        break\n",
    "    \n",
    "    if not cropped_image is None:\n",
    "        feature_test = feature_extractor.extract_image(cropped_image)\n",
    "        prediction = predict(image_representation_database, image_representation_labels, feature_test, THRESHOLD)\n",
    "        if prediction == None:\n",
    "            label = labels[idx]\n",
    "            if label not in image_representation_labels:\n",
    "                image_representation_labels.append(label)\n",
    "                image_representation_database.append(feature_test)\n",
    "                prediction_result.append(label)\n",
    "            else: # false prediction\n",
    "                prediction_result.append(-1) \n",
    "        else:\n",
    "            prediction_result.append(prediction)\n",
    "    else: # failed to detect faces\n",
    "        prediction_result.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.0405996 ,  0.02309781,  0.04990761,  0.000695  ,  0.0563635 ,\n",
       "        0.0356246 , -0.04111306, -0.02143851,  0.09322309, -0.05160348,\n",
       "        0.06762894, -0.04011588,  0.02762367, -0.02471023, -0.00265883,\n",
       "       -0.04618575, -0.03693787,  0.03868102,  0.03121728, -0.0021389 ,\n",
       "       -0.04605038,  0.02138399,  0.01972781, -0.10215669, -0.06483322,\n",
       "        0.00368038,  0.00234469, -0.00917574, -0.03859585,  0.01891637,\n",
       "        0.0174926 ,  0.08110538,  0.05090515,  0.02109467,  0.07272021,\n",
       "       -0.05845511,  0.02789485, -0.06416457,  0.00062212,  0.02790122,\n",
       "        0.06465936, -0.06553471, -0.01928616,  0.04141424,  0.00961436,\n",
       "       -0.03530344, -0.05076744,  0.02497929, -0.05561506, -0.07793365,\n",
       "       -0.0517925 , -0.04527229, -0.03888135,  0.06378752,  0.03055776,\n",
       "       -0.00371595,  0.05760859, -0.05149259, -0.01650976, -0.00538056,\n",
       "        0.02541253,  0.05328941, -0.01167208, -0.02779511,  0.00093871,\n",
       "        0.03193406,  0.02281582, -0.0697334 , -0.03571099, -0.0482035 ,\n",
       "        0.07665833, -0.02865227, -0.03199726, -0.03053773,  0.01251254,\n",
       "        0.02637675,  0.0444779 , -0.00915591, -0.06805602, -0.01629479,\n",
       "        0.01491012,  0.03703761,  0.00500747, -0.02138987,  0.03978988,\n",
       "       -0.01959624,  0.01777292, -0.01942197,  0.02077037, -0.0081926 ,\n",
       "        0.03044065, -0.01757136,  0.06167242, -0.03365153,  0.03125226,\n",
       "        0.07036066, -0.06722509,  0.05613649, -0.08347125,  0.04267213,\n",
       "        0.00842126, -0.00996625,  0.01694414,  0.06045746, -0.0877417 ,\n",
       "        0.05532516,  0.08254152,  0.03380671, -0.0736439 ,  0.05729099,\n",
       "       -0.01763048, -0.00367116, -0.08180256,  0.02146986, -0.08783986,\n",
       "        0.03709968, -0.03167723,  0.13955079,  0.09369849,  0.08287423,\n",
       "       -0.03429756, -0.06798115,  0.02424973,  0.04266802, -0.04382304,\n",
       "        0.01434441,  0.0112617 , -0.05952314, -0.06665591, -0.07174639,\n",
       "       -0.00938744, -0.06984967, -0.01059024, -0.00574664, -0.00655927,\n",
       "        0.08483452, -0.00601659, -0.092143  , -0.06850684, -0.02289909,\n",
       "       -0.04655938,  0.00788579, -0.12336409,  0.0257613 ,  0.03724345,\n",
       "        0.0064388 , -0.01808694,  0.0276493 , -0.03197677, -0.04029594,\n",
       "        0.04539656,  0.05066975, -0.06095414,  0.00937684,  0.02518198,\n",
       "        0.00292068, -0.04446094, -0.00380244,  0.04612332,  0.01172854,\n",
       "       -0.00754887,  0.02960019, -0.06508376,  0.03877367, -0.01678343,\n",
       "       -0.03349703,  0.03407691,  0.02311045,  0.01203016,  0.06799596,\n",
       "       -0.00805841,  0.09266844, -0.02595233, -0.04235341, -0.01820788,\n",
       "       -0.01194672,  0.01256526, -0.02180055, -0.06746831, -0.03461294,\n",
       "        0.0689067 ,  0.10206757, -0.0384642 ,  0.05495955,  0.0306428 ,\n",
       "        0.0070378 ,  0.00769602,  0.02901466,  0.05837632, -0.0206459 ,\n",
       "        0.02945714,  0.00166189,  0.03583157, -0.00044665, -0.01911541,\n",
       "       -0.07755684,  0.01202721, -0.00345191, -0.02021987,  0.00464565,\n",
       "        0.06140899, -0.03442643,  0.04815833,  0.04783299, -0.05205467,\n",
       "        0.04240221, -0.03498458, -0.03793606,  0.02478095,  0.11193639,\n",
       "        0.06663261, -0.06582577, -0.05147599,  0.01091813, -0.03773253,\n",
       "       -0.04305256, -0.01133838, -0.00143788,  0.03615655,  0.01000484,\n",
       "        0.05433447, -0.01324434,  0.00185179, -0.00093451, -0.04674502,\n",
       "        0.04669616,  0.07908859, -0.05666319, -0.08289876,  0.03582447,\n",
       "        0.00712229,  0.00837611,  0.00126071,  0.03746495, -0.02245907,\n",
       "        0.08939728, -0.02616379,  0.02170709, -0.04032295,  0.0939277 ,\n",
       "       -0.03737875,  0.06418748,  0.00294981, -0.01945706, -0.04593494,\n",
       "       -0.0372762 , -0.00369811, -0.02163187,  0.03785956,  0.03646215,\n",
       "        0.00121079, -0.05486564, -0.00932726, -0.02025357,  0.03248547,\n",
       "        0.06099514,  0.04830851,  0.01533043,  0.02167031,  0.03319782,\n",
       "       -0.01286795,  0.04893918,  0.07164922, -0.03667044, -0.04109159,\n",
       "        0.04509444,  0.01385063,  0.02487315, -0.0553987 , -0.09020282,\n",
       "        0.01918811, -0.01100878,  0.02341603, -0.02591465,  0.0891805 ,\n",
       "        0.03454984,  0.00827412, -0.03881953,  0.01590255, -0.00264567,\n",
       "        0.0242672 ,  0.08552974, -0.03209005,  0.00139648, -0.05735633,\n",
       "       -0.04507357,  0.00916167,  0.0228835 ,  0.01506606, -0.00474149,\n",
       "       -0.00266251, -0.01925029, -0.02776312, -0.02537483, -0.01079488,\n",
       "       -0.0248004 ,  0.06338087, -0.03939152,  0.00418681,  0.00329412,\n",
       "       -0.08851498, -0.00242928, -0.01707047, -0.00767939, -0.03652543,\n",
       "        0.0143734 ,  0.02557349,  0.06456787, -0.07458942, -0.00467917,\n",
       "       -0.04602271,  0.02404913,  0.09510897, -0.0068846 , -0.04195381,\n",
       "        0.06102661, -0.00109485, -0.00218936,  0.07027155,  0.00478919,\n",
       "        0.03834618, -0.02921196,  0.04510743, -0.00779778,  0.05560363,\n",
       "       -0.0873649 ,  0.1310507 ,  0.05227681,  0.04737115,  0.00882193,\n",
       "        0.03702903, -0.01764874,  0.03368804,  0.06035671, -0.0049551 ,\n",
       "        0.0874732 , -0.00844991, -0.02838333,  0.01591925, -0.07639156,\n",
       "       -0.01113482, -0.00746237,  0.01112365, -0.01137924, -0.01264616,\n",
       "       -0.00645218, -0.00920107,  0.04692714, -0.11003058,  0.03985985,\n",
       "       -0.05961012,  0.0037424 , -0.02191773,  0.08609194,  0.00578053,\n",
       "       -0.00365593,  0.08343964, -0.01444226,  0.06132307,  0.0358226 ,\n",
       "       -0.04012153,  0.05222118, -0.00714043,  0.00636513, -0.03704103,\n",
       "        0.00881476, -0.07578108,  0.03554903, -0.01770908,  0.06500635,\n",
       "        0.0495563 , -0.04020493, -0.07336073, -0.01599056, -0.06584237,\n",
       "        0.0232191 ,  0.08822542, -0.01045121,  0.02239568, -0.03918083,\n",
       "        0.01899382, -0.05592778,  0.04002862, -0.07216051, -0.06317939,\n",
       "       -0.02124006, -0.03613928, -0.03562154,  0.03687773, -0.0279276 ,\n",
       "        0.00397939, -0.00893038, -0.01950654, -0.06839326,  0.0928549 ,\n",
       "       -0.01436214,  0.0332476 ,  0.02431899, -0.00344501, -0.00293478,\n",
       "       -0.00481316,  0.00911217, -0.05133952,  0.01117483,  0.04378147,\n",
       "        0.02016319, -0.03558307, -0.07658647,  0.06442879, -0.00960646,\n",
       "       -0.02655129,  0.00337564,  0.0808764 , -0.04640727,  0.05287053,\n",
       "       -0.01664516,  0.00899922,  0.01462864,  0.00455562,  0.04500131,\n",
       "       -0.00447639, -0.01158684,  0.00852281,  0.05136787,  0.00876484,\n",
       "        0.00880059, -0.06607694, -0.0075301 , -0.04693431, -0.0478278 ,\n",
       "       -0.01018471,  0.01486977, -0.03774753,  0.00961038, -0.00268953,\n",
       "       -0.03903586,  0.04987942, -0.06857228, -0.04477508, -0.04681743,\n",
       "       -0.02736776, -0.02789991, -0.0590969 ,  0.02406126, -0.00663962,\n",
       "       -0.00253844,  0.00537526, -0.07997348, -0.10191512,  0.05990433,\n",
       "       -0.03141918,  0.02640186, -0.0557414 , -0.00904237, -0.0583589 ,\n",
       "       -0.00808031, -0.06523198,  0.01879715, -0.01294315,  0.07221001,\n",
       "       -0.01105961,  0.02889255, -0.09512731, -0.03831328,  0.01470159,\n",
       "        0.03285049, -0.04870488, -0.04558823,  0.06630285, -0.03114345,\n",
       "        0.03567588,  0.00664671, -0.01037144, -0.01413804,  0.05565646,\n",
       "       -0.0015965 , -0.03132971,  0.04578359,  0.00385032,  0.02305083,\n",
       "        0.02747379, -0.01102665,  0.00095472,  0.04405718, -0.07429598,\n",
       "        0.02044548, -0.01036564, -0.03024135, -0.06468343, -0.00702884,\n",
       "       -0.03479941,  0.02994942, -0.01111798, -0.07829624, -0.00533216,\n",
       "       -0.04165597, -0.03205758, -0.08425379, -0.03973427, -0.00707773,\n",
       "       -0.04793596, -0.03488314, -0.01621788, -0.01317569,  0.021545  ,\n",
       "        0.01504014, -0.01458226, -0.06649791, -0.01080988, -0.01783211,\n",
       "       -0.04272348, -0.00986931], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_feature = feature_test.copy()\n",
    "base_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 0\n",
      "0.0\n",
      "0.9304068088531494\n",
      "0.6869785785675049\n",
      "0.8082365989685059\n",
      "0.7290970087051392\n",
      "0.6848490238189697\n",
      "0.43748414516448975\n",
      "0.8663362264633179\n",
      "0.9823824167251587\n",
      "0.7026365399360657\n",
      "0.7057827115058899\n",
      "0.490217924118042\n",
      "0.5257407426834106\n",
      "0.653395414352417\n",
      "0.6979514956474304\n",
      "0.7552499175071716\n",
      "0.609197199344635\n",
      "0.7848309278488159\n",
      "0.8689273595809937\n",
      "CPU times: user 11.1 s, sys: 11.2 s, total: 22.3 s\n",
      "Wall time: 3.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for idx, image_path in enumerate(image_path_list[31:50]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"Checkpoint\", idx)\n",
    "    img = cv.cvtColor(cv.imread(image_path), cv.COLOR_BGR2RGB)\n",
    "    detection_result = mtcnn_detector.detect_faces(img)\n",
    "    cropped_image = None\n",
    "    for face in detection_result:\n",
    "        face_bbox = face['box']\n",
    "        x, y, w, h = face_bbox\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        break\n",
    "    \n",
    "    if not cropped_image is None:\n",
    "        feature_test = feature_extractor.extract_image(cropped_image)\n",
    "        distance = euclidean(feature_test, base_feature)\n",
    "        print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 0\n",
      "1.4091931581497192\n",
      "1.5989396572113037\n",
      "1.648654580116272\n",
      "1.3955048322677612\n",
      "1.460929274559021\n",
      "1.4296987056732178\n",
      "1.4172757863998413\n",
      "1.4773813486099243\n",
      "1.46343994140625\n",
      "1.2700440883636475\n",
      "1.5592588186264038\n",
      "1.5224809646606445\n",
      "1.114401936531067\n",
      "1.562196969985962\n",
      "1.490476369857788\n",
      "1.2941749095916748\n",
      "1.4539159536361694\n",
      "1.4876363277435303\n",
      "1.250456690788269\n",
      "1.4930957555770874\n",
      "1.5765728950500488\n",
      "1.395493745803833\n",
      "1.510777473449707\n",
      "1.0394794940948486\n",
      "1.4601694345474243\n",
      "1.3177711963653564\n",
      "1.2360012531280518\n",
      "1.2233175039291382\n",
      "1.2125657796859741\n",
      "1.2607898712158203\n",
      "AVG: 1.4010698239008585\n",
      "CPU times: user 16.2 s, sys: 16.6 s, total: 32.8 s\n",
      "Wall time: 4.96 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = []\n",
    "for idx, image_path in enumerate(image_path_list[0:30]):\n",
    "    if idx % 1000 == 0:\n",
    "        print(\"Checkpoint\", idx)\n",
    "    img = cv.cvtColor(cv.imread(image_path), cv.COLOR_BGR2RGB)\n",
    "    detection_result = mtcnn_detector.detect_faces(img)\n",
    "    cropped_image = None\n",
    "    for face in detection_result:\n",
    "        face_bbox = face['box']\n",
    "        x, y, w, h = face_bbox\n",
    "        if x < 0:\n",
    "            x = 0\n",
    "        if y < 0:\n",
    "            y = 0\n",
    "        cropped_image = img[y:y+h, x:x+w]\n",
    "        break\n",
    "    \n",
    "    if not cropped_image is None:\n",
    "        feature_test = feature_extractor.extract_image(cropped_image)\n",
    "        distance = euclidean(feature_test, base_feature)\n",
    "        print(distance)\n",
    "        scores.append(distance)\n",
    "print(\"AVG:\", np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
